\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,natbib,graphicx,amsthm,
  setspace,sectsty,anysize,times,dsfont,enumerate}

\usepackage[svgnames]{xcolor}

\usepackage{lscape,arydshln,relsize,rotating,multirow}
\usepackage{caption}
\captionsetup{%
  font=small,
  labelfont=normalfont,
  singlelinecheck=false,
  justification=justified
}
\usepackage{algorithm,algorithmic}

\newtheorem{prop}{\sc Proposition}[section]
\newtheorem{theorem}{\sc Theorem}[section]
\newtheorem{definition}{\sc Definition}[section]
\newtheorem{lemma}{\sc Lemma}[section]
\newtheorem{corollary}{\sc Corollary}[section]

\marginsize{1.1in}{.9in}{.3in}{1.4in}

\newcommand{\nb}{\color{blue}}
\newcommand{\dbl}{\setstretch{1.5}}
\newcommand{\sgl}{\setstretch{1.4}}

\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mr}[1]{\mathrm{#1}}
\newcommand{\bm}[1]{\mathbf{#1}}
\newcommand{\ds}[1]{\mathds{#1}}
\newcommand{\indep}{\perp\!\!\!\perp}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\norm}[1]{|\!|#1|\!|_{1}}
\newcommand{\code}[1]{{\smaller\sf#1}}
\newcommand{\e}[1]{{\footnotesize$\times10$}{$^{#1}$}}

\usepackage[bottom,hang,flushmargin]{footmisc}

\pdfminorversion=4
\begin{document}

\sgl 

\pagestyle{empty}

\noindent {\Large \bf Comment: \textit{Coauthorship and citation networks for
statisticians}} 

\vskip .5cm

\noindent{\large Mladen Kolar -- University of Chicago Booth School of Business\\Matt Taddy -- 
{Microsoft Research and Chicago Booth}}

 

\vskip 1cm\noindent
This article by Ji and Jin (JJ throughout) provides a network analysis, by two experts in the field, on the connections between statistics research papers.
This is not just an exercise in navel-gazing.  It gives us the opportunity to compare results from the methods we advocate to our intuition in an area we know well: our profession.  And we think that the article contains some lessons for how we use network models and what data we choose to analyze.  First, one can gain insight into network

\subsection*{Topic analysis}

In our first study, we consider decomposing the abstracts of the articles into latent `topics', e.g., as in the LDA of \cite{blei_latent_2003}.  The properties of the citation network can then be considered in light of the topical {\it content} of the articles.

We use the {\tt maptpx} R package \citep{taddy_estimation_2012} to obtain posterior maximizing point estimates for LDA topics.  The {\tt maptpx} package applies the Bayes factors of \cite{taddy_estimation_2012} in model selection, and for this data we find that a 15 topic decomposition is optimal. The full code to fit this model (and all of our other analyses) and to generate summaries for each topic are at {\tt https://github.com/TaddyLab/statsArticles}.  

We focus on topics that have seen their usage change over time -- their
mean proportions within documents during the first and last five years
differ by more than 0.01.  Most topics were stable over time, so that
only three meet this threshold.   These three topics are shown in
the left panel of Figure \ref{fig:topics}.  The list of words given for each topic are those with the highest {\it lift}: within-topic probability over the average corpus-wide occurrence rate.  

Topic 1 seems to contain traditional mathematical statistics content, especially for non and semi parametric analysis.  The three articles most representative of this topic (i.e., have the highest estimated usage) are 

{\it Backfitting and smooth backfitting for additive quantile models} \citep{lee2010backfitting}

{\it Depth weighted scatter estimators} \citep{zuo2005depth}, and

{\it Estimating invariant laws of linear processes by U-statistics} \citep{schick2004estimating}.

This topic remains relatively popular, but its usage is decreasing over time.
The other topic that is decreasing in popularity, topic 4, appears to represent Bayesian analysis.  Its three most representative articles are

{\it A conjugate prior for discrete hierarchical log-linear models} \citep{massam2009conjugate}

{\it Bayesian analysis of variable-order, reversible {M}arkov chains}
\citep{bacallado2011bayesian}

{\it Recapture models under equality constraints for the conditional capture probabilities
} 

\vskip -.25cm
\citep{farcomeni2011recapture}

 Over the same time period, we see a dramatic rise in the prevalence of topic 8, which appears to represent the material related to the popular penalized-deviance 
estimation framework. Its three most representative articles are

{\it The adaptive lasso and its oracle properties} \citep{zou2006adaptive}

{\it Regularization and variable selection via the elastic net} \citep{zou2005regularization}

{\it On the adaptive elastic-net with a diverging number of parameters} \citep{zou2009adaptive}

Thus, our topic model shows an increased interest in penalized deviance estimation (and techniques popular in both statistics and machine learning).  This rise in popularity for topic 8 has come at the expense of  Bayesian analysis and another topic that is roughly interpretable as a different flavor of flexible analysis.  Certainly, the authors' personal experience supports the loss of market share for fully Bayesian analysis; as datasets have grown in size we are often maximizing posteriors (which yields penalized deviance estimators) rather than averaging over them \citep[][are personal examples]{taddy_estimation_2012,taddy_one-step_2015}.

This topic decomposition can be related back to the document networks.  For example, we might be interested in which topics tend to generate higher citations.  A linear regression of citations per year (the total count divided by the years since publication) onto a year indicator (i.e, a publication-date-specific intercept) and the document-topic weights yields an estimated extra 0.1 citations for  per extra 0.1 weight  on topic 8, our penalized deviance topic. This has a $z$-value of around 100, and it is the {\it only} topic that has a significant effect on citations.   Note that this is only the 8th most common topic in our sample, so the higher cite count is not a function of prevalence alone.  It is impossible to tell whether the topic is gaining popularity because it tends to lead to citations, or (what seems more likely) if these papers are cited often because the topic is becoming popular.

\begin{figure}
\includegraphics[width=0.5\textwidth]{lda}
\includegraphics[width=0.5\textwidth]{stm}
\caption{\label{fig:topics} Annual average document-topic weights (that proportion of document devoted to each topic) for topics that saw their usage change by more than 0.1 between the first and last five years of our sample.  The left panel shows  topics from LDA via {\tt maptpx} and the right shows topics from STM via {\tt stm}. }
\end{figure}

This analysis is a simple two stage procedure: we first estimate the topics and then relate them to network statistics (cite counts, i.e., degree in the citation network).
A more complex procedure, such as the recent work by \cite{TanChanZheng2015}, could be used to jointly estimate network communities and text topics (e.g., to see if authors tend to cite within rather than across topics).  As a partial step in this direction, we also applied the structural topic model (STM) of \cite{roberts2013structural} as implemented in the {\tt stm} package for R \citep{roberts2014stm}.  STM assumes that document-topic proportions are generated around a linear function of document attributes.  Applying STM with both citations-per-year and publication date (annual indicators) as inputs yields the topics in the right panel of Figure \ref{fig:topics}.  We  used 15 topics, as in our earlier LDA.  Again, a topic that focuses on penalized deviance estimation shows the biggest gains in usage over time.  Two other topics are also gaining in popularity: one focused on classification (perhaps including much of the machine learning material that was also included in LDA's topic 8) and another that is tough for us to interpret.  There is only one big loser over time: topic 15, which is also tough to interpret.  Across both models, STM and LDA, the point of clear agreement is that penalized deviance estimation is a well-defined topic that is gaining in popularity.  As we found in our two stage estimation, this topic is associated with higher citations: the fitted STM has a posterior mean effect of an extra 0.5 citations-per-year for an extra 0.1 usage of the penalized deviance topic.

\subsection*{Sensitivity of the citation networks to journal choice}

One issue that we have with JJ's analysis is that it includes only a small portion of the statistics publication venues.  Excluded are any applied journals (except for the Applications and Case Studies section of JASA), journals from other fields that use statistics and cite our work, and the entire machine learning literature.  Certain network statistics, such as the betweenness scores that JJ report, are especially sensitive to any missingness in the network.  But we also find that even simple degree statistics (i.e., citation counts) are sensitive to the set of journals considered.


\setstretch{1}\small
\bibliographystyle{chicago}
\bibliography{taddy}

\end{document}
