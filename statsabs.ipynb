{"nbformat_minor": 0, "cells": [{"source": "#### Statistics Citations and Abtstracts", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "papers = sc.textFile('wasb:///statsabs/paperMeta.txt')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "## ... copious amounts of logging info\nimport logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 14, "cell_type": "code", "source": "import re\nheader = re.sub('\\\"','', papers.first()).split(\",\")\nheader", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[u'paperDOI', u'year', u'title', u'citCounts', u'abstract']"}], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "papers.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[u'\"paperDOI\",\"year\",\"title\",\"citCounts\",\"abstract\"', u'\"10.1214/12-AOS1008\",\"2012\",\"Rerandomization to improve covariate balance in experiments\",\"0\",\"Randomized experiments are the \"\"gold standard\"\" for estimating causal effects, yet often in practice, chance imbalances exist in covariate distributions between treatment groups. If covariate data are available before units are exposed to treatments, these chance imbalances can be mitigated by first checking covariate balance before the physical experiment takes place. Provided a precise definition of imbalance has been specified in advance, unbalanced randomizations can be discarded, followed by a rerandomization, and this process can continue until a randomization yielding balance according to the definition is achieved. By improving covariate balance, rerandomization provides more precise and trustworthy estimates of treatment effects.\"']"}], "metadata": {"collapsed": false}}, {"execution_count": 28, "cell_type": "code", "source": "contractions = re.compile(r\"'|-|\\\"\")\n# all non alphanumeric\nsymbols = re.compile(r'(\\W+)', re.U)\n# single character removal\nsingles = re.compile(r'(\\s\\S\\s)', re.I|re.U)\n# separators (any whitespace)\nseps = re.compile(r'\\s+')\n\n# cleaner (order matters)\ndef clean(text): \n    text = text.lower()\n    text = contractions.sub('', text)\n    text = symbols.sub(r' \\1 ', text)\n    text = singles.sub(' ', text)\n    text = seps.sub(' ', text)\n    return text\n\n# sentence splitter\nalteos = re.compile(r'([!\\?])')\ndef sentences(l):\n    l = alteos.sub(r' \\1 .', l).rstrip(\"(\\.)*\\n\")\n    return l.split(\".\")\n\n\ndef YelpReviews(label):\n    with ZipFile(\"yelp_%s_set.zip\"%label, 'r') as zf:\n        with zf.open(\"yelp_%s_set/yelp_%s_set_review.json\"%(label,label)) as f:\n            for line in f:\n                rev = json.loads(line)\n                yield {'y':rev['stars'],\\\n                       'x':[clean(s).split() for s in sentences(rev['text'])]}", "outputs": [{"output_type": "stream", "name": "stderr", "text": "No module named gensim\nTraceback (most recent call last):\n  File \"/var/tmp/spark/1277699391582446158\", line 90, in execute\n    exec code in global_dict\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named gensim\n\n"}], "metadata": {"scrolled": true, "collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"name": "python"}}}}