{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics Citations and Abtstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## spark version\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# spark_home = os.environ['SPARK_HOME']\n",
    "# sys.path.insert(0, spark_home + \"/python/\")\n",
    "# sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "\n",
    "# # Initialize PySpark to predefine the SparkContext variable 'sc'\n",
    "# execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))\n",
    "\n",
    "# papers = sc.textFile('SCC2015-metadata/paperMeta.txt')\n",
    "# papers.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ... copious amounts of logging info\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    " \n",
    "contractions = re.compile(r\"'|-|\\\"}{\")\n",
    "# all non alphanumeric\n",
    "symbols = re.compile(r'(\\W+)', re.U)\n",
    "# single character removal\n",
    "singles = re.compile(r'(\\s\\S\\s)', re.I|re.U)\n",
    "# separators (any whitespace)\n",
    "seps = re.compile(r'\\s+')\n",
    " \n",
    "# cleaner (order matters)\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = contractions.sub('', text)\n",
    "    text = symbols.sub(r' \\1 ', text)\n",
    "    text = singles.sub(' ', text)\n",
    "    text = seps.sub(' ', text)\n",
    "    return text\n",
    " \n",
    "# sentence splitter\n",
    "alteos = re.compile(r'([!\\?])')\n",
    "def sentences(l):\n",
    "    l = alteos.sub(r' \\1 .', l).rstrip(\"(\\.)*\\n\")\n",
    "    return l.split(\".\")\n",
    " \n",
    "def abstractReader():\n",
    "    with open('SCC2015-metadata/paperMeta.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = reader.next()\n",
    "        for l in reader:\n",
    "            text = l[2] + '.  '  + l[4]\n",
    "            text = [clean(s).split() for s in sentences(text)]\n",
    "            wrds = [w for s in text for w in s]\n",
    "            counter = wrds.count # minor speedup\n",
    "            tkncnt = dict((w,counter(w)) for w in set(wrds))\n",
    "            yield {'doi':l[0],'year':int(l[1]),'cites':int(l[3]),'text':tkncnt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts = abstractReader()\n",
    "xout = open('statsAbsTkns.txt', 'w')\n",
    "i = 0\n",
    "for a in abstracts:\n",
    "    i+=1\n",
    "    for w in a['text']:\n",
    "        xout.write(u\"{0}\\t{1}\\t{2}\\n\".format(a['doi'],w,a['text'][w]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
